{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "Deep learning has found applications in medical diagnosis, image recognition, self driving cars and even in competions against humans in a game of Go or Jeopardy.\n",
    "\n",
    "Neural networks lies at the heart of deep learning. They are called so as they mimic the functioning of neurons in human brain.\n",
    "\n",
    "## Perceptron\n",
    "\n",
    "Perceptrons form the building blocks of Neural Networks.\n",
    "\n",
    "![Perceptron](./images/perceptron.png \"Perceptron\")\n",
    "\n",
    "In the figure above X1, X2, .... Xn forms input, W1, W2,... Wn form the weights, and b is the bias. Together they form the input nodes. The input multiplied by the weights and the bias is fed to the \"linear function\" node, which performs the necessary calculations and supplies the output to a \"step function\" node. The step functions returns a \"0\", or \"1\" as the final output.\n",
    "\n",
    "### Perceptron algorithm\n",
    "\n",
    "The perceptron step works as follows. For a point with coordinates (p,q), label y,and prediction given by the equation $\\hat{y} = step(w_1x_1 + w_2x_2 + b)$\n",
    "\n",
    "* If the point is correctly classified, do nothing.\n",
    "* If the point is classified positive, but it has a negative label, subtract $\\alpha p, \\alpha q$ and $\\alpha$ from $w_1, w_2$, and $b$ respectively.\n",
    "* If the point is classified negative, but it has a positive label, add $\\alpha p, \\alpha q$, and $\\alpha$ to $w_1, w_2$ and $b$ respectively."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Functions\n",
    "\n",
    "When the linear function can no longer clearly separate the points of interest, we use an error function to do the job.\n",
    "\n",
    "A sigmod function can be used to convert discrete (Yes/No) values to continous (numeric probablities) values.\n",
    "\n",
    "$$\\sigma(x) = 1/(1 + e^{-x})$$\n",
    "\n",
    "![Perceptron](./images/perceptron2.png \"Perceptron\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
